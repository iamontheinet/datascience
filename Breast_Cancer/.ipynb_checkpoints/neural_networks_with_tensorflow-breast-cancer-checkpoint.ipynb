{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks with TensorFlow -- Binary Classification for Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "target = 1 - data.target\n",
    "\n",
    "# MUST reshape target (y) to be list of lists for TensorFlow \n",
    "target = data.target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean radius',\n",
       " 'mean texture',\n",
       " 'mean perimeter',\n",
       " 'mean area',\n",
       " 'mean smoothness',\n",
       " 'mean compactness',\n",
       " 'mean concavity',\n",
       " 'mean concave points',\n",
       " 'mean symmetry',\n",
       " 'mean fractal dimension',\n",
       " 'radius error',\n",
       " 'texture error',\n",
       " 'perimeter error',\n",
       " 'area error',\n",
       " 'smoothness error',\n",
       " 'compactness error',\n",
       " 'concavity error',\n",
       " 'concave points error',\n",
       " 'symmetry error',\n",
       " 'fractal dimension error',\n",
       " 'worst radius',\n",
       " 'worst texture',\n",
       " 'worst perimeter',\n",
       " 'worst area',\n",
       " 'worst smoothness',\n",
       " 'worst compactness',\n",
       " 'worst concavity',\n",
       " 'worst concave points',\n",
       " 'worst symmetry',\n",
       " 'worst fractal dimension']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10866029, -0.43633778, -0.1629593 , -0.22848008,  0.2200272 ,\n",
       "        -0.49442708, -0.55323932, -0.45239241, -0.29839028, -0.29942571,\n",
       "        -0.62098286, -0.52150393, -0.70008294, -0.4536807 , -1.31276428,\n",
       "        -0.97038837, -0.48289931, -0.44842986, -0.96091682, -0.87672706,\n",
       "        -0.25585074, -0.38517446, -0.3303219 , -0.32741978, -0.55032765,\n",
       "        -0.75138443, -0.4596545 , -0.36165306, -0.60956607, -0.80740465],\n",
       "       [ 2.33955594,  0.04206598,  2.53096201,  2.47641853,  2.60278348,\n",
       "         3.29174724,  4.25358297,  3.49660385,  2.73436154,  1.04935334,\n",
       "         3.17266736,  0.53725695,  3.88663289,  3.15873166, -0.19578116,\n",
       "         3.28419994,  2.21539182,  1.98354227,  1.26469637,  0.42164823,\n",
       "         2.50675536,  0.34733023,  2.94639079,  2.57682546,  1.65068655,\n",
       "         2.71659888,  3.18346447,  2.66911501,  1.87899686,  0.72950295],\n",
       "       [-0.08580646, -0.8723215 , -0.13769343, -0.18579696, -0.59558092,\n",
       "        -0.73227477, -0.99402033, -1.02005735, -1.50192164, -0.6398116 ,\n",
       "        -0.17912546, -1.33997489, -0.33740485, -0.243263  , -0.22413272,\n",
       "        -0.78750839, -0.76937956, -1.0070945 , -1.03157121, -0.4923518 ,\n",
       "        -0.19212992, -1.3711127 , -0.26775092, -0.2925376 , -1.10715794,\n",
       "        -0.9201502 , -1.1035686 , -1.23426845, -1.67655564, -0.88889497],\n",
       "       [-0.74571072, -0.81576145, -0.77348206, -0.71414478, -0.40913564,\n",
       "        -0.8919917 , -0.80069754, -0.6719849 , -0.65908164,  0.10336425,\n",
       "        -0.90358423, -0.84807897, -0.95628178, -0.65660076,  0.71830044,\n",
       "        -0.95076699, -0.71793777, -0.90429771, -0.38837265, -0.32788354,\n",
       "        -0.75945081, -0.83317957, -0.80580237, -0.69307527,  0.90532317,\n",
       "        -0.89007921, -0.81150773, -0.74445347, -0.07040442,  0.1721091 ],\n",
       "       [-0.41433023,  0.29894288, -0.39532244, -0.4900584 ,  0.20778947,\n",
       "         0.29897446,  0.21677091,  0.29731418, -0.28734871,  1.09331985,\n",
       "        -0.2333818 ,  0.99343649, -0.080125  , -0.45755045,  1.98865525,\n",
       "         0.77678211,  0.57229314,  1.69452394,  0.08549901,  0.73727946,\n",
       "        -0.59089895, -0.06797377, -0.530431  , -0.60352699, -0.1644925 ,\n",
       "        -0.19660529, -0.24012254, -0.06301123, -1.08234445,  0.02162363]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features used in training\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.52731161, -0.62487128, -1.50867737, -1.19980949,  0.53676821,\n",
       "        -0.59597787, -1.12715058, -1.28045002,  0.63278231,  1.13303154,\n",
       "         0.44774997,  1.48144251,  0.16634476, -0.25511412,  2.98266775,\n",
       "        -0.34846636, -1.00941026, -1.89086571, -0.25437295,  1.04958436,\n",
       "        -1.24044027, -0.50453349, -1.26800126, -0.96866185,  0.59402435,\n",
       "        -0.7734774 , -1.26645761, -1.73558713, -0.72776067,  0.22752253],\n",
       "       [-0.66857906, -1.13155507, -0.63721205, -0.64694771, -1.11244467,\n",
       "        -0.16731452, -0.27839791, -0.5889171 , -1.15595238,  0.6508182 ,\n",
       "        -0.81888188, -1.05990187, -0.81845329, -0.63749387, -0.03626094,\n",
       "         0.70848668,  0.23616954,  0.49626953,  0.22680779,  1.08136924,\n",
       "        -0.77178387, -1.35476215, -0.75916928, -0.69654613, -1.10277345,\n",
       "         0.13663041, -0.02059059, -0.13717976, -0.47032312,  0.77839715],\n",
       "       [-0.52288591, -0.36563772, -0.55602992, -0.54802669, -0.71291907,\n",
       "        -0.7397615 , -0.63690316, -0.66962651,  0.57757444, -0.10086728,\n",
       "        -0.71114987, -0.45767415, -0.74332325, -0.55356865, -0.53634145,\n",
       "        -0.56744535, -0.39111648, -0.65292987, -0.33477277, -0.52191913,\n",
       "        -0.53745568, -0.10885015, -0.60126608, -0.53966309, -0.47140683,\n",
       "        -0.48013179, -0.36656184, -0.49273458,  0.35380084, -0.17069354],\n",
       "       [-0.30863128,  0.54874977, -0.17372836, -0.376429  ,  2.22125453,\n",
       "         1.68689923,  1.21871801,  1.17044328,  1.97617358,  1.54574942,\n",
       "        -0.37429215, -0.42284184, -0.24497868, -0.36467644, -0.46358384,\n",
       "         0.48408742,  0.09229376,  0.02446663,  0.08428084, -0.05438575,\n",
       "        -0.14690869,  0.79206522, -0.0227796 , -0.23578897,  1.65945553,\n",
       "         1.73714368,  1.22990792,  1.38251817,  2.40196747,  1.23528626],\n",
       "       [ 1.29399335,  0.17875277,  1.25938476,  1.27956074, -0.14710444,\n",
       "         0.02446098,  0.75307761,  0.74540865, -0.42720862, -0.8511345 ,\n",
       "         1.75927015,  1.07477083,  1.4986868 ,  1.3094745 ,  1.25083154,\n",
       "         0.0613062 ,  0.5660916 ,  1.0946156 ,  0.2670077 ,  0.11858312,\n",
       "         1.04939842,  0.2247011 ,  0.97186296,  0.91601716,  0.05911652,\n",
       "        -0.27822656,  0.329549  ,  0.51974146, -0.89614749, -0.5569577 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine features used in testing\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# shape None == allow dynamic number of rows; X_train.shape[1] == number of features\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, X_train.shape[1]), name='inputs')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None), name='targets')\n",
    "\n",
    "# First hidden layer\n",
    "# X == features coming in, 30 == number of features == neurons\n",
    "h1 = tf.layers.dense(X, 30, name='input_layer_1', activation=tf.nn.relu)\n",
    "\n",
    "# Second hidden layer\n",
    "# h1 == features coming in, 26 == number of neurons == arbitrary\n",
    "h2 = tf.layers.dense(h1, 26, name='input_layer_2', activation=tf.nn.relu)\n",
    "\n",
    "# Last/output layar always has 1 neuron for binary classification problems\n",
    "y_hat = tf.layers.dense(h2, 1, name='y_hat', activation=tf.nn.sigmoid)\n",
    "final_output = tf.identity(y_hat, name='classifications') \n",
    "\n",
    "loss = tf.losses.log_loss(y, y_hat)\n",
    "\n",
    "# Define training operation\n",
    "training_op = tf.train.AdamOptimizer(.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model and save/export it using TensorFlow Serving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  | training loss: 0.61675286  | test loss: 0.6248219\n",
      "epoch: 100  | training loss: 0.00030252174  | test loss: 0.24269032\n",
      "epoch: 200  | training loss: 6.68025e-05  | test loss: 0.29234645\n",
      "epoch: 300  | training loss: 3.0104544e-05  | test loss: 0.3077362\n",
      "epoch: 400  | training loss: 1.7146984e-05  | test loss: 0.3185355\n",
      "epoch: 500  | training loss: 1.1088368e-05  | test loss: 0.32272467\n",
      "epoch: 600  | training loss: 7.753676e-06  | test loss: 0.32627067\n",
      "epoch: 700  | training loss: 5.713634e-06  | test loss: 0.32928047\n",
      "epoch: 800  | training loss: 4.371246e-06  | test loss: 0.3319225\n",
      "epoch: 900  | training loss: 3.4393101e-06  | test loss: 0.33427384\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./models/saved_model.pb\n",
      "\n",
      "Accuracy Score: 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# If model already exists, delete it\n",
    "try:\n",
    "    if os.path.isfile('./models/saved_model.pb'):\n",
    "        shutil.rmtree('./models')\n",
    "except OSError as e:\n",
    "    print('OSError: ', e.strerror)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    # Train model with 1000 epochs\n",
    "    for epoch in range(1000):\n",
    "        sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        if (epoch % 100 == 0):\n",
    "            training_loss = sess.run(loss, feed_dict={X: X_train, y: y_train})\n",
    "            test_loss = sess.run(loss, feed_dict={X: X_test, y: y_test})\n",
    "            print('epoch:',epoch,' | training loss:', training_loss, ' | test loss:', test_loss)\n",
    "\n",
    "    # Get the tensors needed for serving\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs = graph.get_tensor_by_name('inputs:0')\n",
    "    classifications = graph.get_tensor_by_name('classifications:0')\n",
    "    \n",
    "    # Create tensors info needed for serving\n",
    "    model_input = tf.saved_model.utils.build_tensor_info(inputs)\n",
    "    model_output = tf.saved_model.utils.build_tensor_info(classifications)\n",
    "\n",
    "    # Build signature definition needed for serving\n",
    "    signature_definition = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'inputs': model_input},\n",
    "        outputs={'outputs': model_output},\n",
    "        method_name= tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME)\n",
    "\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder('./models')\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess, [tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "                signature_definition\n",
    "        })\n",
    "    \n",
    "    # Save the model so it can be served with a TF model server\n",
    "    builder.save()\n",
    "    \n",
    "    # Use model to classify test data\n",
    "    classifications_on_test_data = sess.run(y_hat, feed_dict={X: X_test})\n",
    "    \n",
    "    # Check model accuracy\n",
    "    classes = (classifications_on_test_data > .5).astype(int)\n",
    "    \n",
    "    print('\\nAccuracy Score:',metrics.accuracy_score(y_test, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
